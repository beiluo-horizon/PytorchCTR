base:
    model_name: FATDeepFFM
    batch_size: 1000
    early_stop_patience: 2
    embedding_dim: 10
    embedding_regularizer: 1.0e-05
    net_regularizer: 0
    epochs: 100
    eval_epoch: 2
    learning_rate: 1.0e-4
    loss: binary_crossentropy
    batch_normal: true
    dropout: 0.5
    linear_dropout: 0.0
    hidden_activations: relu
    hidden_units: [400, 400, 400]
    optimizer: adam
    num_workers: 8
    use_linear: True
    ce_dim: 10
    reduction: 8
